{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3.2:3b\"\n",
    "\n",
    "client = OpenAI(\n",
    "        base_url=\"http://localhost:11434/v1\",\n",
    "        api_key=\"nokeyneeded\" # nokeyneeded\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?"
     ]
    }
   ],
   "source": [
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "\n",
    "for chunk in stream:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    text.append(content)\n",
    "    \n",
    "print(\"\".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assistant:\n",
    "    def __init__(self, \n",
    "                 host = 'http://localhost:11434/v1', \n",
    "                 model = \"llama3.2:3b\",\n",
    "                 system_prompt = \"You are a helpful assistant.\"\n",
    "                 ):\n",
    "        self.client = OpenAI(\n",
    "        base_url=host,\n",
    "        api_key=\"nokeyneeded\"\n",
    "        )\n",
    "        self.model = model\n",
    "        self.system_prompt = system_prompt\n",
    "        \n",
    "    def get_stream(self, user_text: str):\n",
    "        # Getting Stream Generator Object\n",
    "        stream = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": user_text}],\n",
    "            stream=True\n",
    "        )\n",
    "        return stream\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello A! It's nice to meet you. Is there something I can help you with or would you like to chat?"
     ]
    }
   ],
   "source": [
    "a1 = Assistant()\n",
    "stream1 = a1.get_stream(\"Hello, my name is A\")\n",
    "\n",
    "for chunk in stream1:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have any information about your personal details, including your name. This conversation just started, and I'm here to help answer your questions and provide assistance. What would you like to talk about?"
     ]
    }
   ],
   "source": [
    "stream1 = a1.get_stream(\"What's my name\")\n",
    "\n",
    "for chunk in stream1:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
